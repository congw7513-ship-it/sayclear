import { NextRequest, NextResponse } from "next/server";
import { AnalyzeResponse, AnalysisResult } from "@/types/analysis";
import { MOCK_MODE, MOCK_ANALYSIS_RESULT } from "@/lib/mock-data";

// ============================================
// API é…ç½®
// ============================================

// MiniMax æ–‡æœ¬åˆ†æ API
const MINIMAX_API_URL = "https://api.minimax.chat/v1/text/chatcompletion_v2";
const MINIMAX_MODEL = "MiniMax-Text-01";

// æœ¬åœ° Faster-Whisper STT æœåŠ¡
const LOCAL_WHISPER_URL = "http://localhost:5000/transcribe";

// System Prompt for Logic Master
const SYSTEM_PROMPT = `# Role
You are "Logic Master," a senior communication coach specializing in workplace reporting. Your goal is to analyze the user's spoken transcript (which may contain minor STT errors) and provide a rigorous critique based strictly on logical structure and efficiency. You do not care about politeness; you care about clarity and impact.

# Context
The user is practicing a "Workplace Report" (e.g., status update, proposal). The ideal structure is the **PREP model**:
1. **Point (P)**: State the conclusion immediately.
2. **Reason (R)**: Explain why.
3. **Example/Evidence (E)**: Provide data, cases, or facts.
4. **Point (P)**: Reiterate the conclusion or call to action.

# Task
Analyze the user's input text following these steps:

1. **Pre-processing**: 
   - Ignore minor homophone errors caused by speech-to-text (STT) unless they make the sentence unintelligible.
   - Remove filler words (e.g., "um," "ah," "like," "you know") from your logical analysis but count them for the "Efficiency" score.

2. **Structural Analysis (PREP Detection)**:
   - Did the user start with the Conclusion (Point)?
   - Is there a logical link between the Reason and the Point?
   - Is the Evidence specific (numbers, facts) or vague?

3. **Scoring (0-100)**:
   - **Logic Score**: How strong is the argument? (Deduct points for logical fallacies, circular reasoning, or missing evidence).
   - **Structure Score**: How well does it fit PREP? (Deduct points heavily if the conclusion is buried at the end).
   - **Efficiency Score**: 100 minus the percentage of fluff/filler words and repetitive sentences.

4. **Feedback Generation**:
   - Provide a "One-Sentence Diagnosis" (The most critical issue).
   - Identify specific segments in the text to highlight as "Good" (Green) or "Bad" (Red).

# Constraints
- Be objective and critical. Do not give false praise.
- If the input is too short (under 10 words) or nonsensical, return an error status.
- Output strictly in JSON format.
- IMPORTANT: Respond in Chinese (Simplified) for all text fields.

# Output JSON Format
{
  "scores": {
    "logic": <int>,
    "structure": <int>,
    "efficiency": <int>
  },
  "diagnosis": "<string: A punchy, 1-sentence summary of the main problem IN CHINESE>",
  "prep_analysis": {
    "point_detected": <boolean>,
    "conclusion_position": "<string: 'start', 'middle', 'end', or 'missing'>"
  },
  "advice": [
    "<string: Specific actionable advice 1 IN CHINESE>",
    "<string: Specific actionable advice 2 IN CHINESE>"
  ],
  "segments": [
    {
      "text": "<string: excerpt from user text>",
      "type": "<string: 'highlight_good' or 'highlight_bad'>",
      "comment": "<string: specific critique for this segment IN CHINESE>"
    }
  ]
}`;

// ä½¿ç”¨æœ¬åœ° Faster-Whisper è¿›è¡Œè¯­éŸ³è½¬æ–‡å­—
// ============================================
async function transcribeAudioWithLocalWhisper(
    audioFile: File
): Promise<string> {
    console.log("ğŸ¤ [STT] å¼€å§‹è¯­éŸ³è½¬æ–‡å­— (æœ¬åœ° Whisper)...");
    console.log(`ğŸ¤ [STT] æ–‡ä»¶: ${audioFile.name}, å¤§å°: ${audioFile.size} bytes, ç±»å‹: ${audioFile.type}`);
    console.log("æ­£åœ¨ä½¿ç”¨æœ¬åœ° Faster-Whisper æ¨¡å‹è¿›è¡Œè¯†åˆ«...");

    const formData = new FormData();
    formData.append("file", audioFile);

    const response = await fetch(LOCAL_WHISPER_URL, {
        method: "POST",
        body: formData,
    });

    if (!response.ok) {
        const errorText = await response.text();
        console.error("ğŸ¤ [STT] âŒ è½¬å½•å¤±è´¥:", errorText);

        // å¦‚æœæœ¬åœ°æœåŠ¡æœªå¯åŠ¨ï¼Œè¿”å›æ›´å‹å¥½çš„é”™è¯¯
        if (response.status === 0 || errorText.includes("ECONNREFUSED")) {
            throw new Error("æœ¬åœ° Whisper æœåŠ¡æœªå¯åŠ¨ï¼Œè¯·å…ˆè¿è¡Œ whisper-server/start.bat");
        }
        throw new Error(`STT é”™è¯¯: ${response.status} - ${errorText}`);
    }

    const data = await response.json();
    const transcription = data.text || "";

    console.log("ğŸ¤ [STT Result]:", transcription);
    console.log("ğŸ¤ [STT] âœ… è¯­éŸ³è½¬æ–‡å­—å®Œæˆ!");

    return transcription;
}

// ============================================
// ä½¿ç”¨ MiniMax è¿›è¡Œé€»è¾‘åˆ†æ
// ============================================
async function analyzeWithMiniMax(
    text: string,
    apiKey: string
): Promise<AnalysisResult> {
    console.log("ğŸ§  [LLM] å¼€å§‹é€»è¾‘åˆ†æ...");
    console.log("ğŸ§  [LLM] è¾“å…¥æ–‡æœ¬:", text.substring(0, 200) + (text.length > 200 ? "..." : ""));

    const response = await fetch(MINIMAX_API_URL, {
        method: "POST",
        headers: {
            "Content-Type": "application/json",
            Authorization: `Bearer ${apiKey}`,
        },
        body: JSON.stringify({
            model: MINIMAX_MODEL,
            messages: [
                { role: "system", content: SYSTEM_PROMPT },
                { role: "user", content: text },
            ],
            temperature: 0.7,
        }),
    });

    if (!response.ok) {
        const errorText = await response.text();
        console.error("ğŸ§  [LLM] âŒ åˆ†æå¤±è´¥:", errorText);
        throw new Error(`LLM é”™è¯¯: ${response.status} - ${errorText}`);
    }

    const data = await response.json();
    const content = data.choices?.[0]?.message?.content;

    if (!content) {
        throw new Error("LLM è¿”å›äº†ç©ºå“åº”");
    }

    console.log("ğŸ§  [LLM] åŸå§‹å“åº”:", content.substring(0, 300) + "...");

    // å°è¯•ä»å†…å®¹ä¸­æå– JSONï¼ˆå¤„ç†å¯èƒ½çš„ markdown ä»£ç å—ï¼‰
    let jsonContent = content;
    const jsonMatch = content.match(/```(?:json)?\s*([\s\S]*?)```/);
    if (jsonMatch) {
        jsonContent = jsonMatch[1].trim();
    }

    const analysisResult: AnalysisResult = JSON.parse(jsonContent);
    console.log("ğŸ§  [LLM] âœ… åˆ†æå®Œæˆ! åˆ†æ•°:", analysisResult.scores);

    return analysisResult;
}

// ============================================
// POST è¯·æ±‚å¤„ç† - æ ¸å¿ƒæ•°æ®æµ
// ============================================
export async function POST(request: NextRequest) {
    console.log("\n" + "=".repeat(50));
    console.log("ğŸ“¥ [API] æ”¶åˆ°æ–°è¯·æ±‚");
    console.log("=".repeat(50));

    try {
        // ============================================
        // Step 1: æ£€æŸ¥ MOCK æ¨¡å¼
        // ============================================
        if (MOCK_MODE) {
            console.log("ğŸ­ [MOCK MODE] è¿”å›æ¨¡æ‹Ÿæ•°æ®ï¼Œè·³è¿‡çœŸå® API");
            await new Promise((resolve) => setTimeout(resolve, 1500));
            return NextResponse.json<AnalyzeResponse>({
                success: true,
                data: MOCK_ANALYSIS_RESULT,
            });
        }

        console.log("ğŸš€ [REAL MODE] è¿›å…¥çœŸå®å¤„ç†æµç¨‹");

        // ============================================
        // Step 2: è§£æè¯·æ±‚ï¼Œè·å–æ–‡æœ¬å†…å®¹
        // ============================================
        const contentType = request.headers.get("content-type") || "";
        let textToAnalyze: string = "";

        // ------------------------------------------
        // æƒ…å†µ A: FormData (éŸ³é¢‘æ–‡ä»¶ä¸Šä¼ )
        // ------------------------------------------
        if (contentType.includes("multipart/form-data")) {
            console.log("ğŸ“¦ [API] æ¥æ”¶åˆ° FormData (éŸ³é¢‘ä¸Šä¼ )");

            const formData = await request.formData();
            const audioFile = formData.get("file") as File | null;

            if (audioFile && audioFile.size > 0) {
                console.log(`ğŸµ [API] æ£€æµ‹åˆ°éŸ³é¢‘æ–‡ä»¶: ${audioFile.name} (${audioFile.size} bytes)`);

                // ğŸ”‘ å…³é”®æ­¥éª¤: è°ƒç”¨æœ¬åœ° Whisper å°†éŸ³é¢‘è½¬ä¸ºæ–‡å­—
                textToAnalyze = await transcribeAudioWithLocalWhisper(audioFile);

            } else {
                // FormData ä¸­æ²¡æœ‰æœ‰æ•ˆéŸ³é¢‘ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æ–‡æœ¬
                const textInput = formData.get("text") as string | null;
                if (textInput) {
                    textToAnalyze = textInput;
                    console.log("ğŸ“ [API] FormData ä¸­æ‰¾åˆ°æ–‡æœ¬è¾“å…¥");
                }
            }
        }
        // ------------------------------------------
        // æƒ…å†µ B: JSON (æ–‡æœ¬è¾“å…¥)
        // ------------------------------------------
        else if (contentType.includes("application/json")) {
            console.log("ğŸ“ [API] æ¥æ”¶åˆ° JSON (æ–‡æœ¬è¾“å…¥)");
            const body = await request.json();
            textToAnalyze = body.text || "";
        }
        // ------------------------------------------
        // æƒ…å†µ C: ä¸æ”¯æŒçš„æ ¼å¼
        // ------------------------------------------
        else {
            console.error("âŒ [API] ä¸æ”¯æŒçš„ Content-Type:", contentType);
            return NextResponse.json<AnalyzeResponse>(
                { success: false, error: `ä¸æ”¯æŒçš„è¯·æ±‚æ ¼å¼: ${contentType}` },
                { status: 400 }
            );
        }

        // ============================================
        // Step 3: éªŒè¯è¾“å…¥æ–‡æœ¬
        // ============================================
        if (!textToAnalyze || textToAnalyze.trim().length === 0) {
            console.error("âŒ [API] æ²¡æœ‰å¯åˆ†æçš„æ–‡æœ¬");
            return NextResponse.json<AnalyzeResponse>(
                { success: false, error: "æ²¡æœ‰æ£€æµ‹åˆ°è¯­éŸ³å†…å®¹æˆ–æ–‡æœ¬ï¼Œè¯·é‡æ–°å½•éŸ³" },
                { status: 400 }
            );
        }

        if (textToAnalyze.trim().length < 10) {
            console.error("âŒ [API] æ–‡æœ¬å¤ªçŸ­:", textToAnalyze);
            return NextResponse.json<AnalyzeResponse>(
                { success: false, error: "å½•éŸ³å†…å®¹å¤ªçŸ­ï¼ˆå°‘äº10ä¸ªå­—ï¼‰ï¼Œè¯·å½•åˆ¶æ›´é•¿çš„å†…å®¹" },
                { status: 400 }
            );
        }

        console.log("âœ… [API] å¾…åˆ†ææ–‡æœ¬:", textToAnalyze.substring(0, 100) + "...");

        // ============================================
        // Step 4: è°ƒç”¨ LLM è¿›è¡Œé€»è¾‘åˆ†æ
        // ============================================
        const llmApiKey = process.env.MINIMAX_API_KEY;
        if (!llmApiKey) {
            console.error("âŒ [API] MINIMAX_API_KEY æœªé…ç½®");
            return NextResponse.json<AnalyzeResponse>(
                { success: false, error: "åˆ†ææœåŠ¡æœªé…ç½® (ç¼ºå°‘ MINIMAX_API_KEY)" },
                { status: 500 }
            );
        }

        // ğŸ”‘ å…³é”®æ­¥éª¤: ç”¨ STT è½¬å½•çš„æ–‡æœ¬ï¼ˆæˆ–ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬ï¼‰è¿›è¡Œåˆ†æ
        const analysisResult = await analyzeWithMiniMax(textToAnalyze, llmApiKey);

        console.log("âœ… [API] åˆ†æå®Œæˆï¼Œè¿”å›ç»“æœ");
        console.log("=".repeat(50) + "\n");

        return NextResponse.json<AnalyzeResponse>({
            success: true,
            data: analysisResult,
        });

    } catch (error) {
        console.error("âŒ [API] å¤„ç†é”™è¯¯:", error);
        return NextResponse.json<AnalyzeResponse>(
            {
                success: false,
                error: error instanceof Error ? error.message : "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯",
            },
            { status: 500 }
        );
    }
}
